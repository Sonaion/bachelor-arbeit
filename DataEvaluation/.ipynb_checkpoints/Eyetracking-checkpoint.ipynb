{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Data Analysis for REYeker</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lib for dataframes\n",
    "# lib for crerating paths\n",
    "from pathlib import Path\n",
    "\n",
    "# lib for plotting\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# REYeker lib\n",
    "import modules.rEYEkerAnalysis as rEYEker\n",
    "\n",
    "# lib for numerical computations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sonaion_analysis as son\n",
    "\n",
    "# lib for saving np images\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>1. Configuration</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Database configuration </h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the datafile\n",
    "config_datasheet_path = r\"./results/preprocessed.xlsx\"\n",
    "\n",
    "# columns with visual stimulus data\n",
    "config_visual_stimulus_variable = \"ClickData\"\n",
    "\n",
    "# colums of response time\n",
    "config_visual_time_variable = \"TimeData\"\n",
    "\n",
    "# columns with programming style\n",
    "config_programming_style_variable = \"ProgrammingStyle\"\n",
    "\n",
    "# columns with names of the algo\n",
    "config_algo_name_variable = \"Algorithm\"\n",
    "\n",
    "# columns with correctness value\n",
    "config_corectness_variable = \"Correctness\"\n",
    "\n",
    "# colums of response time\n",
    "config_response_time_variable = \"ResponseTime\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "click_settings = rEYEker.load_settings_from_json(\"./data/settings.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Import the preprocessed dataframe</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "needed_columns = [\n",
    "    \"ID\",\n",
    "    config_programming_style_variable,\n",
    "    config_algo_name_variable,\n",
    "    config_corectness_variable,\n",
    "    config_response_time_variable,\n",
    "    config_visual_stimulus_variable,\n",
    "    config_visual_time_variable,\n",
    "]\n",
    "\n",
    "raw = pd.read_excel(config_datasheet_path)\n",
    "df = pd.DataFrame(raw, columns=needed_columns)\n",
    "algo_name_array = [name for name in df[config_algo_name_variable].unique()]\n",
    "\n",
    "df_tensor = []\n",
    "\n",
    "for algo_name in algo_name_array:\n",
    "    algo_df = df.loc[df[config_algo_name_variable] == algo_name]\n",
    "    df_array = [\n",
    "        algo_df.loc[algo_df[config_programming_style_variable] == \"iterative\"],\n",
    "        algo_df.loc[algo_df[config_programming_style_variable] == \"recursive\"],\n",
    "        algo_df.loc[algo_df[config_programming_style_variable] == \"higher-order\"],\n",
    "        algo_df.loc[algo_df[config_programming_style_variable] == \"list-comprehension\"],\n",
    "    ]\n",
    "    df_tensor.append(df_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data for loading the images\n",
    "image_path_tensor = []\n",
    "\n",
    "for algo_name in algo_name_array:\n",
    "    image_path_array = [\n",
    "        \"./data/images/\" + algo_name + \"_iterative.png\",\n",
    "        \"./data/images/\" + algo_name + \"_recursive.png\",\n",
    "        \"./data/images/\" + algo_name + \"_higher_order.png\",\n",
    "        \"./data/images/\" + algo_name + \"_list_comprehension.png\",\n",
    "    ]\n",
    "    image_path_tensor.append(image_path_array)\n",
    "\n",
    "# where to save to heatmaps and sequence diagrams\n",
    "config_folder_prefix_array = [\"Iterative/\", \"Recursive/\", \"HigherOrder/\", \"ListComprehension/\"]\n",
    "\n",
    "# used for saving the heatmaps and sequence diagrams\n",
    "config_image_prefix_tensor = []\n",
    "for algo_name in algo_name_array:\n",
    "    image_prefix_array = [\n",
    "        \"Iteraitive_\" + algo_name + \"_\",\n",
    "        \"Recursive_\" + algo_name + \"_\",\n",
    "        \"Higher-Order_\" + algo_name + \"_\",\n",
    "        \"List-Comprhension_\" + algo_name + \"_\",\n",
    "    ]\n",
    "    config_image_prefix_tensor.append(image_prefix_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Import Images Settings</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor = []\n",
    "\n",
    "# read in every image\n",
    "for image_path_array in image_path_tensor:\n",
    "    image_array = []\n",
    "    for image_path in image_path_array:\n",
    "        img = rEYEker.load_image(image_path)\n",
    "        image_array.append(img)\n",
    "    image_tensor.append(image_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Cast Data to Valid format</h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the visual stimulus measured Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_stimulus_data_tensor = []\n",
    "time_data_tensor = []\n",
    "\n",
    "# iter over every dataframe\n",
    "for df_array in df_tensor:\n",
    "\n",
    "    visual_stimulus_data_matrix = []\n",
    "    time_data_matrix = []\n",
    "    for idx, dataframe in enumerate(df_array):\n",
    "        visual_stimulus_array = []\n",
    "        time_data_array = []\n",
    "\n",
    "        # iter over every row\n",
    "        for _idx, row in dataframe.iterrows():\n",
    "            data_str = row[config_visual_stimulus_variable]\n",
    "            data_str = str(data_str).strip()\n",
    "            coordinates_str = data_str.split(\" \")\n",
    "            coordinates = []\n",
    "\n",
    "            times_str = row[config_visual_time_variable]\n",
    "            times_str = str(times_str).strip()\n",
    "            times_str = times_str.split(\" \")\n",
    "            times = []\n",
    "\n",
    "            # iter over every coordinate pair x-y\n",
    "            for coordinate_str in coordinates_str:\n",
    "                try:\n",
    "                    coordinate = coordinate_str.split(\"-\")\n",
    "                    coordinate = (int(coordinate[0]), int(coordinate[1]))\n",
    "                    coordinates.append(coordinate)\n",
    "                except:\n",
    "                    coordinates.append(None)\n",
    "\n",
    "            for time_str in times_str:\n",
    "                try:\n",
    "                    time_str = int(time_str)\n",
    "                    times.append(time_str)\n",
    "                except:\n",
    "                    times.append(None)\n",
    "\n",
    "            visual_stimulus_array.append(coordinates)\n",
    "            time_data_array.append(times)\n",
    "\n",
    "        visual_stimulus_data_matrix.append(visual_stimulus_array)\n",
    "        time_data_matrix.append(time_data_array)\n",
    "\n",
    "    visual_stimulus_data_tensor.append(visual_stimulus_data_matrix)\n",
    "    time_data_tensor.append(time_data_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Helper Functions</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_images(image_array, folder, image_name):\n",
    "    \"\"\"\n",
    "    :brief saves an array of images to a certain location incrementing the postfix by a number\n",
    "    :param image_array:        array of images (np.ndarray)\n",
    "    :param folder:     prefix of image/ folder location\n",
    "    :param image_name: prefix for the image\n",
    "    \"\"\"\n",
    "\n",
    "    Path(folder).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    prefix = folder + image_name\n",
    "\n",
    "    # TODO create folders if there are none present\n",
    "    for idx, data in enumerate(image_array):\n",
    "        data = data * 255\n",
    "        data = np.uint8(data)\n",
    "        im = Image.fromarray(data)\n",
    "        im.save(prefix + str(idx) + \".png\")\n",
    "\n",
    "\n",
    "def compare_for_h0(arr_1, arr_2, alpha):\n",
    "    t, p = stats.ttest_ind(arr_1, arr_2)\n",
    "    if p > alpha:\n",
    "        return True, t, p\n",
    "    else:\n",
    "        return False, t, p\n",
    "\n",
    "\n",
    "def is_in(value, tup):\n",
    "    return tup[0] <= value <= tup[1]\n",
    "\n",
    "\n",
    "def get_0_offset(number):\n",
    "    i = 0\n",
    "    number = int(number)\n",
    "    while number != 0:\n",
    "        number = int(number / 10)\n",
    "        i = i + 1\n",
    "    return i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>2. Create Single Heatmaps</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to process 12 datatables: \n",
      "\tGoing to process algorithm #0:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t--------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t--------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t------\n",
      "\tGoing to process algorithm #1:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t-------\n",
      "\tGoing to process algorithm #2:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t-------\n",
      "\tGoing to process algorithm #3:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t---------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t-----\n",
      "\tGoing to process algorithm #4:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t--------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t-------\n",
      "\tGoing to process algorithm #5:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t-------\n",
      "\tGoing to process algorithm #6:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t--------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t------\n",
      "\tGoing to process algorithm #7:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t--------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t------\n",
      "\tGoing to process algorithm #8:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t--------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t------\n",
      "\tGoing to process algorithm #9:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t-----\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t--------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t--------\n",
      "\tGoing to process algorithm #10:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t-------\n",
      "\tGoing to process algorithm #11:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t--------\n"
     ]
    }
   ],
   "source": [
    "heatmap_tensor = []\n",
    "\n",
    "print(\"Going to process \" + str(len(visual_stimulus_data_tensor)) + \" datatables: \")\n",
    "for algo_idx in range(len(visual_stimulus_data_tensor)):\n",
    "    heatmaps_matrix = []\n",
    "    print(\"\\tGoing to process algorithm #\" + str(algo_idx) + \":\")\n",
    "\n",
    "    # iterate over all the datasets\n",
    "    for implementation_idx in range(len(visual_stimulus_data_tensor[algo_idx])):\n",
    "\n",
    "        print(\"\\t\\tImplementation Variant #\" + str(implementation_idx) + \":\")\n",
    "        heatmap_array = []\n",
    "\n",
    "        print(\"\\t\\t\\t\", end=\"\")\n",
    "        # iterate over all the measurements of the dataset\n",
    "        for dataset_idx in range(len(visual_stimulus_data_tensor[algo_idx][implementation_idx])):\n",
    "            click_data = visual_stimulus_data_tensor[algo_idx][implementation_idx][dataset_idx]\n",
    "            time_data = time_data_tensor[algo_idx][implementation_idx][dataset_idx]\n",
    "            image = image_tensor[algo_idx][implementation_idx]\n",
    "\n",
    "            print(\"-\", end=\"\")\n",
    "            try:\n",
    "                im = rEYEker.draw_shape_heat_map(image, click_data, click_settings, should_copy=True, time_stamps=time_data)\n",
    "                heatmap_array.append(im)\n",
    "            except:\n",
    "                heatmap_array.append(image)\n",
    "\n",
    "        print()\n",
    "        heatmaps_matrix.append(heatmap_array)\n",
    "\n",
    "    heatmap_tensor.append(heatmaps_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "save Heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:./results/Iterative/apply/heatmaps/\n",
      "Writing to:./results/Recursive/apply/heatmaps/\n",
      "Writing to:./results/HigherOrder/apply/heatmaps/\n",
      "Writing to:./results/ListComprehension/apply/heatmaps/\n",
      "Writing to:./results/Iterative/condition_sum/heatmaps/\n",
      "Writing to:./results/Recursive/condition_sum/heatmaps/\n",
      "Writing to:./results/HigherOrder/condition_sum/heatmaps/\n",
      "Writing to:./results/ListComprehension/condition_sum/heatmaps/\n",
      "Writing to:./results/Iterative/find/heatmaps/\n",
      "Writing to:./results/Recursive/find/heatmaps/\n",
      "Writing to:./results/HigherOrder/find/heatmaps/\n",
      "Writing to:./results/ListComprehension/find/heatmaps/\n",
      "Writing to:./results/Iterative/is_prime/heatmaps/\n",
      "Writing to:./results/Recursive/is_prime/heatmaps/\n",
      "Writing to:./results/HigherOrder/is_prime/heatmaps/\n",
      "Writing to:./results/ListComprehension/is_prime/heatmaps/\n",
      "Writing to:./results/Iterative/max/heatmaps/\n",
      "Writing to:./results/Recursive/max/heatmaps/\n",
      "Writing to:./results/HigherOrder/max/heatmaps/\n",
      "Writing to:./results/ListComprehension/max/heatmaps/\n",
      "Writing to:./results/Iterative/node/heatmaps/\n",
      "Writing to:./results/Recursive/node/heatmaps/\n",
      "Writing to:./results/HigherOrder/node/heatmaps/\n",
      "Writing to:./results/ListComprehension/node/heatmaps/\n",
      "Writing to:./results/Iterative/prime_factors/heatmaps/\n",
      "Writing to:./results/Recursive/prime_factors/heatmaps/\n",
      "Writing to:./results/HigherOrder/prime_factors/heatmaps/\n",
      "Writing to:./results/ListComprehension/prime_factors/heatmaps/\n",
      "Writing to:./results/Iterative/quad_mul/heatmaps/\n",
      "Writing to:./results/Recursive/quad_mul/heatmaps/\n",
      "Writing to:./results/HigherOrder/quad_mul/heatmaps/\n",
      "Writing to:./results/ListComprehension/quad_mul/heatmaps/\n",
      "Writing to:./results/Iterative/students/heatmaps/\n",
      "Writing to:./results/Recursive/students/heatmaps/\n",
      "Writing to:./results/HigherOrder/students/heatmaps/\n",
      "Writing to:./results/ListComprehension/students/heatmaps/\n",
      "Writing to:./results/Iterative/computer/heatmaps/\n",
      "Writing to:./results/Recursive/computer/heatmaps/\n",
      "Writing to:./results/HigherOrder/computer/heatmaps/\n",
      "Writing to:./results/ListComprehension/computer/heatmaps/\n",
      "Writing to:./results/Iterative/store/heatmaps/\n",
      "Writing to:./results/Recursive/store/heatmaps/\n",
      "Writing to:./results/HigherOrder/store/heatmaps/\n",
      "Writing to:./results/ListComprehension/store/heatmaps/\n",
      "Writing to:./results/Iterative/LinkedList/heatmaps/\n",
      "Writing to:./results/Recursive/LinkedList/heatmaps/\n",
      "Writing to:./results/HigherOrder/LinkedList/heatmaps/\n",
      "Writing to:./results/ListComprehension/LinkedList/heatmaps/\n"
     ]
    }
   ],
   "source": [
    "for algo_idx, heatmaps_matrix in enumerate(heatmap_tensor):\n",
    "    for idx, heatmap_array in enumerate(heatmaps_matrix):\n",
    "        path = \"./results/\" + config_folder_prefix_array[idx] + str(algo_name_array[algo_idx]) + \"/heatmaps/\"\n",
    "        print(\"Writing to:\" + path)\n",
    "        save_images(heatmap_array, path, config_image_prefix_tensor[algo_idx][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>3. Create Average Heatmaps</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to process 12 datatables: \n",
      "\tGoing to process algorithm #0:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\tImplementation Variant #1:\n",
      "\t\tImplementation Variant #2:\n",
      "\t\tImplementation Variant #3:\n",
      "\n",
      "\tGoing to process algorithm #1:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\tImplementation Variant #1:\n",
      "[[None], [(67, 17), (81, 40), (100, 62), (103, 94), (192, 120), (156, 171), (103, 248), (73, 35), (100, 62), (119, 91), (240, 118), (190, 89), (77, 37), (133, 92)], [(117, 246), (88, 43), (101, 66), (121, 90), (124, 114), (121, 152), (132, 174), (153, 93), (152, 114), (148, 142), (146, 178), (120, 244), (106, 16), (109, 54), (116, 89), (119, 106), (121, 116), (129, 174), (154, 95), (165, 169), (167, 86), (147, 167), (159, 116), (160, 92), (165, 163), (163, 97), (133, 123), (122, 248)], [(75, 15), (94, 49), (100, 238), (127, 85), (140, 169), (186, 95)], [(176, 131), (177, 119), (159, 168), (28, 130), (64, 144), (86, 254), (128, 252), (130, 127), (123, 184), (114, 287), (117, 249)], [(88, 6), (95, 42), (83, 67), (133, 94), (200, 115), (181, 150), (180, 166), (145, 246)], [(105, 19), (105, 38), (113, 65), (149, 92), (156, 117), (119, 144), (152, 170), (121, 248)]]\n",
      "\t\tImplementation Variant #2:\n",
      "\t\tImplementation Variant #3:\n",
      "\n",
      "\tGoing to process algorithm #2:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\tImplementation Variant #1:\n",
      "\t\tImplementation Variant #2:\n"
     ]
    }
   ],
   "source": [
    "heatmap_tensor = []\n",
    "mask_tensor = []\n",
    "\n",
    "print(\"Going to process \" + str(len(visual_stimulus_data_tensor)) + \" datatables: \")\n",
    "for algo_idx in range(len(visual_stimulus_data_tensor)):\n",
    "    if algo_idx == 2:\n",
    "        break\n",
    "    average_heatmap_array = []\n",
    "    mask_array = []\n",
    "    print(\"\\tGoing to process algorithm #\" + str(algo_idx) + \":\")\n",
    "\n",
    "    # iterate over all the datasets\n",
    "    for implementation_idx in range(len(visual_stimulus_data_tensor[algo_idx])):\n",
    "        print(\"\\t\\tImplementation Variant #\" + str(implementation_idx) + \":\")\n",
    "\n",
    "        image = image_tensor[algo_idx][implementation_idx]\n",
    "        click = visual_stimulus_data_tensor[algo_idx][implementation_idx]\n",
    "        time = time_data_tensor[algo_idx][implementation_idx]\n",
    "\n",
    "        click_tmp = []\n",
    "        time_tmp = []\n",
    "\n",
    "        for i in range(len(click)):\n",
    "\n",
    "            if click[i] is not None or None not in click[i]:\n",
    "                click_tmp.append(click[i])\n",
    "                time_tmp.append(time[i])\n",
    "\n",
    "        try:\n",
    "            im, mask = rEYEker.draw_average_shape_heat_map_rel(image, click_tmp, click_settings, 1.0, 0.0, time_tmp, should_copy=True)\n",
    "        except:\n",
    "            print(click_tmp)\n",
    "\n",
    "        average_heatmap_array.append(im)\n",
    "        mask_array.append(mask)\n",
    "\n",
    "    print()\n",
    "    heatmap_tensor.append(average_heatmap_array)\n",
    "    mask_tensor.append(mask_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save heatmaps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n",
      "Writing to:./results/averageHeatMaps_of_wrong/\n"
     ]
    }
   ],
   "source": [
    "for algo_idx, heatmaps_matrix in enumerate(heatmap_tensor):\n",
    "    for idx, heatmap in enumerate(heatmaps_matrix):\n",
    "        # path = \"./results/\" + str(algo_name_array[algo_idx]) + \"/heatmaps/average_heatmap/\"\n",
    "        path = \"./results/averageHeatMaps_of_wrong/\"\n",
    "        print(\"Writing to:\" + path)\n",
    "        save_images([heatmap], path, config_image_prefix_tensor[algo_idx][idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>4. Create Sequence diagramms</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create sequence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Going to process 12 datatables: \n",
      "\tGoing to process algorithm #0:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t--------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t--------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t------\n",
      "\tGoing to process algorithm #1:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t-------\n",
      "\tGoing to process algorithm #2:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t-------\n",
      "\tGoing to process algorithm #3:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t---------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t-----\n",
      "\tGoing to process algorithm #4:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t--------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t-------\n",
      "\tGoing to process algorithm #5:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t-------\n",
      "\tGoing to process algorithm #6:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t--------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t------\n",
      "\tGoing to process algorithm #7:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t--------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t------\n",
      "\tGoing to process algorithm #8:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t--------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t------\n",
      "\tGoing to process algorithm #9:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t-----\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t--------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t--------\n",
      "\tGoing to process algorithm #10:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t-------\n",
      "\tGoing to process algorithm #11:\n",
      "\t\tImplementation Variant #0:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #1:\n",
      "\t\t\t------\n",
      "\t\tImplementation Variant #2:\n",
      "\t\t\t-------\n",
      "\t\tImplementation Variant #3:\n",
      "\t\t\t--------\n"
     ]
    }
   ],
   "source": [
    "sequence_tensor = []\n",
    "\n",
    "print(\"Going to process \" + str(len(visual_stimulus_data_tensor)) + \" datatables: \")\n",
    "for algo_idx in range(len(visual_stimulus_data_tensor)):\n",
    "    sequence_matrix = []\n",
    "    print(\"\\tGoing to process algorithm #\" + str(algo_idx) + \":\")\n",
    "\n",
    "    # iterate over all the datasets\n",
    "    for implementation_idx in range(len(visual_stimulus_data_tensor[algo_idx])):\n",
    "\n",
    "        print(\"\\t\\tImplementation Variant #\" + str(implementation_idx) + \":\")\n",
    "        sequence_array = []\n",
    "\n",
    "        print(\"\\t\\t\\t\", end=\"\")\n",
    "        # iterate over all the measurements of the dataset\n",
    "        for dataset_idx in range(len(visual_stimulus_data_tensor[algo_idx][implementation_idx])):\n",
    "            click_data = visual_stimulus_data_tensor[algo_idx][implementation_idx][dataset_idx]\n",
    "            time_data = time_data_tensor[algo_idx][implementation_idx][dataset_idx]\n",
    "            image = image_tensor[algo_idx][implementation_idx]\n",
    "\n",
    "            print(\"-\", end=\"\")\n",
    "            try:\n",
    "                im = rEYEker.draw_vertical_line_diagram(image, click_data, should_copy=True, time_stamps=time_data)\n",
    "                sequence_array.append(im)\n",
    "            except:\n",
    "                sequence_array.append(image)\n",
    "\n",
    "        print()\n",
    "        sequence_matrix.append(sequence_array)\n",
    "\n",
    "    sequence_tensor.append(sequence_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "save sequence diagrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing to:./results/Iterative/apply/sequence/\n",
      "Writing to:./results/Recursive/apply/sequence/\n",
      "Writing to:./results/HigherOrder/apply/sequence/\n",
      "Writing to:./results/ListComprehension/apply/sequence/\n",
      "Writing to:./results/Iterative/condition_sum/sequence/\n",
      "Writing to:./results/Recursive/condition_sum/sequence/\n",
      "Writing to:./results/HigherOrder/condition_sum/sequence/\n",
      "Writing to:./results/ListComprehension/condition_sum/sequence/\n",
      "Writing to:./results/Iterative/find/sequence/\n",
      "Writing to:./results/Recursive/find/sequence/\n",
      "Writing to:./results/HigherOrder/find/sequence/\n",
      "Writing to:./results/ListComprehension/find/sequence/\n",
      "Writing to:./results/Iterative/is_prime/sequence/\n",
      "Writing to:./results/Recursive/is_prime/sequence/\n",
      "Writing to:./results/HigherOrder/is_prime/sequence/\n",
      "Writing to:./results/ListComprehension/is_prime/sequence/\n",
      "Writing to:./results/Iterative/max/sequence/\n",
      "Writing to:./results/Recursive/max/sequence/\n",
      "Writing to:./results/HigherOrder/max/sequence/\n",
      "Writing to:./results/ListComprehension/max/sequence/\n",
      "Writing to:./results/Iterative/node/sequence/\n",
      "Writing to:./results/Recursive/node/sequence/\n",
      "Writing to:./results/HigherOrder/node/sequence/\n",
      "Writing to:./results/ListComprehension/node/sequence/\n",
      "Writing to:./results/Iterative/prime_factors/sequence/\n",
      "Writing to:./results/Recursive/prime_factors/sequence/\n",
      "Writing to:./results/HigherOrder/prime_factors/sequence/\n",
      "Writing to:./results/ListComprehension/prime_factors/sequence/\n",
      "Writing to:./results/Iterative/quad_mul/sequence/\n",
      "Writing to:./results/Recursive/quad_mul/sequence/\n",
      "Writing to:./results/HigherOrder/quad_mul/sequence/\n",
      "Writing to:./results/ListComprehension/quad_mul/sequence/\n",
      "Writing to:./results/Iterative/students/sequence/\n",
      "Writing to:./results/Recursive/students/sequence/\n",
      "Writing to:./results/HigherOrder/students/sequence/\n",
      "Writing to:./results/ListComprehension/students/sequence/\n",
      "Writing to:./results/Iterative/computer/sequence/\n",
      "Writing to:./results/Recursive/computer/sequence/\n",
      "Writing to:./results/HigherOrder/computer/sequence/\n",
      "Writing to:./results/ListComprehension/computer/sequence/\n",
      "Writing to:./results/Iterative/store/sequence/\n",
      "Writing to:./results/Recursive/store/sequence/\n",
      "Writing to:./results/HigherOrder/store/sequence/\n",
      "Writing to:./results/ListComprehension/store/sequence/\n",
      "Writing to:./results/Iterative/LinkedList/sequence/\n",
      "Writing to:./results/Recursive/LinkedList/sequence/\n",
      "Writing to:./results/HigherOrder/LinkedList/sequence/\n",
      "Writing to:./results/ListComprehension/LinkedList/sequence/\n"
     ]
    }
   ],
   "source": [
    "for algo_idx, sequence_matrix in enumerate(sequence_tensor):\n",
    "    for idx, sequence_array in enumerate(sequence_matrix):\n",
    "        path = \"./results/\" + config_folder_prefix_array[idx] + str(algo_name_array[algo_idx]) + \"/sequence/\"\n",
    "        print(\"Writing to:\" + path)\n",
    "        save_images(sequence_array, path, config_image_prefix_tensor[algo_idx][idx])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
